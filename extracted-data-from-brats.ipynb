{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport SimpleITK as sitk \nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%pylab inline\n\nimport os\nimport torch\nfrom PIL import Image\nfrom torch.utils import data\nfrom torchvision import transforms, utils\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport random\nfrom keras.utils import to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T14:51:31.943948Z","iopub.execute_input":"2021-06-19T14:51:31.94457Z","iopub.status.idle":"2021-06-19T14:51:40.438672Z","shell.execute_reply.started":"2021-06-19T14:51:31.944454Z","shell.execute_reply":"2021-06-19T14:51:40.43743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list = []\ntrain_list = []\n\nfor rootname, dirnames, filenames in os.walk('/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/HGG'):\n    for dirname in dirnames:\n        train_list.append(os.path.join(rootname, dirname))\nfor rootname, dirnames, filenames in os.walk('/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/LGG'):\n    for dirname in dirnames:\n        train_list.append(os.path.join(rootname, dirname))\n        \nfor rootname, dirnames, filenames in os.walk('/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/test/HGG_LGG'):\n    for dirname in dirnames:\n        test_list.append(os.path.join(rootname, dirname))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:51:40.440134Z","iopub.execute_input":"2021-06-19T14:51:40.440437Z","iopub.status.idle":"2021-06-19T14:51:42.119604Z","shell.execute_reply.started":"2021-06-19T14:51:40.440406Z","shell.execute_reply":"2021-06-19T14:51:42.118412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/working/features/')\nos.mkdir('/kaggle/working/labels/')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:51:42.122449Z","iopub.execute_input":"2021-06-19T14:51:42.122825Z","iopub.status.idle":"2021-06-19T14:51:42.127281Z","shell.execute_reply.started":"2021-06-19T14:51:42.122791Z","shell.execute_reply":"2021-06-19T14:51:42.126506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_list), len(test_list)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:51:42.128549Z","iopub.execute_input":"2021-06-19T14:51:42.128936Z","iopub.status.idle":"2021-06-19T14:51:42.144714Z","shell.execute_reply.started":"2021-06-19T14:51:42.128907Z","shell.execute_reply":"2021-06-19T14:51:42.143585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_imgs(path, idx):\n    path = path + \"/\"\n    my_dir = sorted(os.listdir(path))\n    imgs = []\n    print(\"{} start\".format(path))\n    for i in range(len(my_dir)):\n        if i != len(my_dir)-1:\n#         if i == 0:\n            img_itk = sitk.ReadImage(path + my_dir[i])\n            # pre-processing\n            # Image Smoothing/Denoising\n            img_itk = sitk.CurvatureFlow(image1=img_itk,timeStep=0.125, numberOfIterations=5)\n            img = sitk.GetArrayFromImage(img_itk)\n            img = np.asarray(img,dtype=np.float32)\n            img = img[30:120,30:222,30:222]\n            imgs.append(img)\n#             features_list.append(img)\n        else:\n            img_itk = sitk.ReadImage(path + my_dir[i])\n            mask = sitk.GetArrayFromImage(img_itk)\n            mask = np.asarray(mask,dtype=np.float32)\n            mask = mask[30:120,30:222,30:222]\n#             labels_list.append(mask)\n    \n    imgs = np.asarray(imgs,dtype=np.float32)\n    imgs = np.moveaxis(imgs, 0, 1)\n    mask = np.asarray(mask,dtype=np.uint8)\n    mask = mask[: , None, :, :]\n\n    np.save('/kaggle/working/features/'+str(idx)+'_data.npy',imgs)\n    np.save('/kaggle/working/labels/'+str(idx)+'_gt.npy',mask)\n#     labels_list = np.concatenate((labels_list, mask))\n    print(imgs.shape, mask.shape)\n    print(str(idx)+\" dir done!\")\n#     print(len(features_list), len(labels_list))\n\n#     return None","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:52:53.248026Z","iopub.execute_input":"2021-06-19T14:52:53.248432Z","iopub.status.idle":"2021-06-19T14:52:53.260515Z","shell.execute_reply.started":"2021-06-19T14:52:53.248396Z","shell.execute_reply":"2021-06-19T14:52:53.259234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\nfor dir_path in train_list:\n    idx += 1\n    load_imgs(dir_path, idx)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:52:54.301947Z","iopub.execute_input":"2021-06-19T14:52:54.302361Z","iopub.status.idle":"2021-06-19T15:34:54.765847Z","shell.execute_reply.started":"2021-06-19T14:52:54.302326Z","shell.execute_reply":"2021-06-19T15:34:54.763473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx","metadata":{"execution":{"iopub.status.busy":"2021-06-19T14:48:03.86691Z","iopub.execute_input":"2021-06-19T14:48:03.867401Z","iopub.status.idle":"2021-06-19T14:48:03.879423Z","shell.execute_reply.started":"2021-06-19T14:48:03.867366Z","shell.execute_reply":"2021-06-19T14:48:03.87798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_list = np.asarray(features_list,dtype=np.float32)\nlabels_list = np.asarray(labels_list,dtype=np.float32)\nprint(features_list.shape, labels_list.shape)\nnew_features_list = features_list.reshape((-1, 4, 240, 240))\nnew_labels_list = labels_list.reshape((-1, 1, 240, 240))\nprint(new_features_list.shape, new_labels_list.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_shape, mask_shape = load_imgs(train_list[0])\nimgs_shape, mask_shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:45:41.462596Z","iopub.execute_input":"2021-06-19T12:45:41.462919Z","iopub.status.idle":"2021-06-19T12:45:49.127601Z","shell.execute_reply.started":"2021-06-19T12:45:41.462893Z","shell.execute_reply":"2021-06-19T12:45:49.126533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(path):\n    path = path + \"/\"\n    my_dir = sorted(os.listdir(path))\n    data = []\n    gt = []\n#     print(my_dir)\n    for i in range(len(my_dir)):\n        if i != len(my_dir)-1:\n            img_itk = sitk.ReadImage(path + my_dir[i])\n            # pre-processing\n            # Image Smoothing/Denoising\n            img_itk = sitk.CurvatureFlow(image1=img_itk,timeStep=0.125, numberOfIterations=5)\n            img = sitk.GetArrayFromImage(img_itk)\n            data.append(img)\n        else:\n            img_itk = sitk.ReadImage(path + my_dir[i])\n            mask = sitk.GetArrayFromImage(img_itk)\n            gt.append(mask)\n            \n    data = np.asarray(data,dtype=np.float32)\n    gt = np.asarray(gt,dtype=np.uint8)\n    \n    return data, gt\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:12:00.175137Z","iopub.execute_input":"2021-06-19T12:12:00.175715Z","iopub.status.idle":"2021-06-19T12:12:00.182276Z","shell.execute_reply.started":"2021-06-19T12:12:00.175678Z","shell.execute_reply":"2021-06-19T12:12:00.18122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sitk_show(img, title=None, margin=0.0, dpi=40):\n    nda = sitk.GetArrayFromImage(img)\n#     nda=numpy.transpose(nda)\n#     print(nda.shape)\n    #spacing = img.GetSpacing()\n    figsize = (1 + margin) * nda.shape[0] / dpi, (1 + margin) * nda.shape[1] / dpi\n    #extent = (0, nda.shape[1]*spacing[1], nda.shape[0]*spacing[0], 0)\n    extent = (0, nda.shape[1], nda.shape[0], 0)\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_axes([margin, margin, 1 - 2*margin, 1 - 2*margin])\n\n    plt.set_cmap(\"gray\")\n    ax.imshow(nda,extent=extent,interpolation=None)\n    print(nda.shape)\n    if title:\n        plt.title(title)\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:23:03.870956Z","iopub.execute_input":"2021-06-19T12:23:03.871276Z","iopub.status.idle":"2021-06-19T12:23:03.878335Z","shell.execute_reply.started":"2021-06-19T12:23:03.871247Z","shell.execute_reply":"2021-06-19T12:23:03.877158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenameTC=\"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/HGG/brats_2013_pat0013_1/VSD.Brain.XX.O.MR_T1c.54586.mha\"\n# Slice index to visualize with 'sitk_show'\nlabel=\"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/HGG/brats_2013_pat0013_1/VSD.Brain_3more.XX.O.OT.54589.mha\"\nimgTCOriginal = sitk.ReadImage(filenameTC)\nlabelOrignal=sitk.ReadImage(label)\nprint(type(imgTCOriginal))\nsitk_show(imgTCOriginal[:, :, 105])\nsitk_show(labelOrignal[:, :, 105])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:26:16.773524Z","iopub.execute_input":"2021-06-19T12:26:16.774002Z","iopub.status.idle":"2021-06-19T12:26:17.337528Z","shell.execute_reply.started":"2021-06-19T12:26:16.773973Z","shell.execute_reply":"2021-06-19T12:26:17.336573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path1 = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/HGG/\"\npath2 = \"/kaggle/input/brain-tumor-segmentation-in-mri-brats-2015/train/LGG/\"\n# data1, gt1 = load_data(path1)\ndata2, gt2 = load_data(train_list[1])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:12:00.54978Z","iopub.execute_input":"2021-06-19T12:12:00.550098Z","iopub.status.idle":"2021-06-19T12:12:08.905382Z","shell.execute_reply.started":"2021-06-19T12:12:00.550071Z","shell.execute_reply":"2021-06-19T12:12:08.904693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.shape,gt2.shape,data2.dtype,gt2.dtype","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:12:09.025469Z","iopub.execute_input":"2021-06-19T12:12:09.026093Z","iopub.status.idle":"2021-06-19T12:12:09.032583Z","shell.execute_reply.started":"2021-06-19T12:12:09.02604Z","shell.execute_reply":"2021-06-19T12:12:09.031801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BraTsDataset(Dataset):\n    def __init__(self, transform=None,train=True):\n        \n        self.transform = transform\n        self.train = train\n        if self.train:\n            self.path_list = train_list\n            self.data_len = len(train_list)\n        else:\n            self.path_list = test_list\n            self.data_len = len(test_list)\n            \n    def __getitem__(self, i):\n        # read data as ndarray\n        features, label = load_data(self.path_list[i])\n        # pre-processing -2\n#         print(i,\"load\")\n        '''Taking Only from 30th slice till 120th slice for creating the data and also cropping \n        the images to discard useless background \n        So, from 240x240x4 each image now becomes of shape 192x192x4 taking all 4 modalities'''\n#         (4, 90, 240, 240)\n#         (1, 90, 240, 240)\n        features = features[:,43:107,30:222,30:222]\n        label = label[:,43:107,30:222,30:222]\n#         print(\"features shape: {}, label shape: {}\".format(features.shape, label.shape))\n#         features = features[:,30:120,30:222,30:222].reshape([-1,192,192,4])\n#         label = label[:,30:120,30:222,30:222].reshape([-1,192,192,1])\n#         image1 = image.transpose(3,0)\n#         image1 = image1.transpose(3,1)\n#         image1 = image1.transpose(3,2)\n        print(features.shape, label.shape)\n        \n        '''The segmentations are combined to generate the final labels of the tumor structures:\n        0 background\n        necrotic/cystic core (綠) (標註為1), \n        edema (黃) (標註為2), \n        non-enhancing solid core (紅) (標註為3)\n        , enhancing core (藍) (標註為4).'''\n        \n        # one-hot encoding\n#         label = np.eye(4)[label]\n        label = to_categorical(label)\n\n        \n        if self.transform:\n            features = self.transform(features)\n            label = self.transform(label)\n        \n        features = torch.from_numpy(features)\n        label = torch.from_numpy(label)\n#         print(\"label shape {}\".format(label.shape))\n#         print(\"label type {}\".format(type(label)))\n        label = label.transpose(4, 1)\n#         print(\"label shape {}\".format(label.shape))\n        label = label.transpose(4, 2)\n#         print(\"label shape {}\".format(label.shape))\n        label = label.transpose(4, 3)\n#         print(\"label shape {}\".format(label.shape))\n#         print(i,\"from_numpy\")\n        print(features.shape, label.shape)\n        return features, label\n    \n    def __len__(self):\n        return self.data_len","metadata":{"execution":{"iopub.status.busy":"2021-06-19T12:12:18.985678Z","iopub.execute_input":"2021-06-19T12:12:18.986164Z","iopub.status.idle":"2021-06-19T12:12:18.99594Z","shell.execute_reply.started":"2021-06-19T12:12:18.986122Z","shell.execute_reply":"2021-06-19T12:12:18.994936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}